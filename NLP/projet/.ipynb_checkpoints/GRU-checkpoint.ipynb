{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = Namespace(\n",
    "    seq_size=32,\n",
    "    batch_size=1,\n",
    "    embedding_size=64,\n",
    "    lstm_size=64,\n",
    "    gradients_norm=5,\n",
    "    initial_words=['Et', 'je'],\n",
    "    predict_top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rap data\n",
    "directory = \"rap/Jul\"\n",
    "txt = \"\"\n",
    "for album in os.listdir(directory):\n",
    "    dir_album = \"{}/{}\".format(directory, album)\n",
    "    for son in os.listdir(dir_album):\n",
    "        adr = \"{}/{}\".format(dir_album,son)\n",
    "        with open(adr, 'rb') as f:\n",
    "            data = f.read()\n",
    "            decoded_data = data.decode('utf8')\n",
    "            txt+=decoded_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##american dad data\n",
    "directory = \"scripts_american_dad\"\n",
    "txt = \"\"\n",
    "for saison in os.listdir(directory):\n",
    "    dir_saison = \"{}/{}\".format(directory, saison)\n",
    "    for ep in os.listdir(dir_saison):\n",
    "        adr = \"{}/{}\".format(dir_saison,ep)\n",
    "        with open(adr, 'r') as f:\n",
    "            data = f.read()\n",
    "            txt+=data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size :  14562\n"
     ]
    }
   ],
   "source": [
    "token = nltk.word_tokenize(txt.lower())\n",
    "words = Counter(token)\n",
    "words = sorted(words, key=words.get, reverse=True)\n",
    "vocab_size = len(words)\n",
    "word2idx = {o:i for i,o in enumerate(words)}\n",
    "idx2word = {i:o for i,o in enumerate(words)}\n",
    "print(\"vocab size : \",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_text = [word2idx[w] for w in token]\n",
    "num_batches = int(len(int_text) / (flags.seq_size * flags.batch_size))\n",
    "in_text = int_text[:num_batches * flags.batch_size * flags.seq_size]\n",
    "out_text = np.zeros_like(in_text)\n",
    "out_text[:-1] = in_text[1:]\n",
    "out_text[-1] = in_text[0]\n",
    "in_text = np.reshape(in_text, (flags.batch_size, -1))\n",
    "out_text = np.reshape(out_text, (flags.batch_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(in_text, out_text, batch_size, seq_size):\n",
    "    num_batches = np.prod(in_text.shape) // (seq_size * batch_size)\n",
    "    for i in range(0, num_batches * seq_size, seq_size):\n",
    "        yield in_text[:, i:i+seq_size], out_text[:, i:i+seq_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, nb_cells, hidden_size, vocab_size, embeddings_dim): \n",
    "        super(Model, self).__init__()\n",
    "        self.gru = nn.GRU(embeddings_dim, hidden_size, nb_cells, batch_first = True)\n",
    "        self.embeddings = nn.Embedding(vocab_size, embeddings_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nb_cells = nb_cells\n",
    "        self.dense1 = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        embeds = self.embeddings(x)\n",
    "        gru_out, hidden = self.gru(embeds, hidden)\n",
    "        out = self.dense1(gru_out)\n",
    "        return out, hidden\n",
    "    \n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.nb_cells, batch_size, self.hidden_size).zero_()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, max_epochs=5):\n",
    "    optim = th.optim.Adam(model.parameters(), lr=lr) #Adam adapté aux pb de NLP\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    print(\"Modèle : \\n\", model)\n",
    "    for epoch in range(max_epochs):\n",
    "        batches = get_batches(in_text, out_text, flags.batch_size, flags.seq_size)\n",
    "        h = model.init_hidden(flags.batch_size)\n",
    "        i=0\n",
    "        print(\"EPOCH {}\".format(epoch))\n",
    "        for x, y in batches:\n",
    "            i+=1\n",
    "            optim.zero_grad()\n",
    "            h = h.data\n",
    "            x = th.LongTensor(x)\n",
    "            y = th.LongTensor(y)\n",
    "            pred, h = model.forward(x, h)\n",
    "            loss = loss_fn(pred.transpose(1, 2), y)\n",
    "            h = h.detach()\n",
    "            loss.backward()  \n",
    "#             nn.utils.clip_grad_norm_(model.parameters(), flags.gradients_norm)\n",
    "            optim.step()\n",
    "\n",
    "            if(i%1000==0):\n",
    "                print(\"{}/{}\".format(i, num_batches))\n",
    "            if(i%5000==0):\n",
    "                print(\"{}/{}\".format(i, num_batches))\n",
    "                model.eval()\n",
    "                predict(model, token[:100], word2idx, idx2word, 50)\n",
    "                print('\\n')\n",
    "                model.train()\n",
    "                \n",
    "        print(\"predict epoch :\\n\")\n",
    "        model.eval()\n",
    "        predict(model, token[:100], word2idx, idx2word, 50)\n",
    "        model.train()\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Hyper paramètres\n",
    "vocab_size = len(word2idx)\n",
    "embedding_dim = 64\n",
    "hidden_dim = 64\n",
    "nb_cells = 1\n",
    "model = Model(nb_cells,hidden_dim, vocab_size, embedding_dim)\n",
    "# model.load_state_dict(th.load(\"model.pth\"))\n",
    "# model2 = Model(nb_cells,hidden_dim, vocab_size, embedding_dim)\n",
    "\n",
    "# model3 = Model(nb_cells,hidden_dim, vocab_size, embedding_dim)\n",
    "\n",
    "lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle : \n",
      " Model(\n",
      "  (gru): GRU(64, 64, batch_first=True)\n",
      "  (embeddings): Embedding(14562, 64)\n",
      "  (dense1): Linear(in_features=64, out_features=14562, bias=True)\n",
      ")\n",
      "EPOCH 0\n",
      "1000/7859\n",
      "2000/7859\n",
      "3000/7859\n",
      "4000/7859\n",
      "5000/7859\n",
      "5000/7859\n",
      "[ couplet 1 ] et je zone , comme un loup j'ai trop faim , ouais de sous et je serre , comme un fou j'suis déter ' , levez-vous j'ai les cernes , je vois flou pour mes frères , j'me mets saoul franchement , je n'sais plus quoi faire trop d'jaloux j'peux plus les compter faire le mac , à quoi ça sert ? tu peux t'faire fumer ou planter j'charme les miss comme calimero en deux-deux j'prends cent numéros ça sert à rien de faire le héros toujours à la base comme mero mero et oui mi pas mon [ [ , je je pas , mon je pas [ [ mon mon je [ [ [ je , [ , mon [ mon mon [ , mon , je [ pas je , pas mon [ pas je , pas mon [ mon [ [ [ [\n",
      "\n",
      "\n",
      "6000/7859\n",
      "7000/7859\n",
      "predict epoch :\n",
      "\n",
      "[ couplet 1 ] et je zone , comme un loup j'ai trop faim , ouais de sous et je serre , comme un fou j'suis déter ' , levez-vous j'ai les cernes , je vois flou pour mes frères , j'me mets saoul franchement , je n'sais plus quoi faire trop d'jaloux j'peux plus les compter faire le mac , à quoi ça sert ? tu peux t'faire fumer ou planter j'charme les miss comme calimero en deux-deux j'prends cent numéros ça sert à rien de faire le héros toujours à la base comme mero mero et oui mi pour le amigo ) beau beau le beau ) , ) tel tel beau corazón quillé amor l'avocat c'qu'ils quillé tel beau corazón amor amor , corazón , c'qu'ils c'qu'ils corazón quillé amor amor amor quillé c'qu'ils amor , c'qu'ils tel quillé beau beau beau amor , , , amor amor\n",
      "\n",
      "\n",
      "EPOCH 1\n",
      "1000/7859\n",
      "2000/7859\n",
      "3000/7859\n",
      "4000/7859\n",
      "5000/7859\n",
      "5000/7859\n",
      "[ couplet 1 ] et je zone , comme un loup j'ai trop faim , ouais de sous et je serre , comme un fou j'suis déter ' , levez-vous j'ai les cernes , je vois flou pour mes frères , j'me mets saoul franchement , je n'sais plus quoi faire trop d'jaloux j'peux plus les compter faire le mac , à quoi ça sert ? tu peux t'faire fumer ou planter j'charme les miss comme calimero en deux-deux j'prends cent numéros ça sert à rien de faire le héros toujours à la base comme mero mero et oui mi sois vers veulent vers corazon veulent sois sois veulent corazon veulent sois corazon corazon veulent corazon sont corazon j'essaie sois sois sois veulent corazon j'essaie sois vers veulent corazon s'engueule veulent freres s'engueule freres s'engueule veulent veulent freres veulent s'engueule freres j'essaie amor freres amor s'engueule j'essaie s'engueule freres corazon amor\n",
      "\n",
      "\n",
      "6000/7859\n",
      "7000/7859\n",
      "predict epoch :\n",
      "\n",
      "[ couplet 1 ] et je zone , comme un loup j'ai trop faim , ouais de sous et je serre , comme un fou j'suis déter ' , levez-vous j'ai les cernes , je vois flou pour mes frères , j'me mets saoul franchement , je n'sais plus quoi faire trop d'jaloux j'peux plus les compter faire le mac , à quoi ça sert ? tu peux t'faire fumer ou planter j'charme les miss comme calimero en deux-deux j'prends cent numéros ça sert à rien de faire le héros toujours à la base comme mero mero et oui mi pas un corazón corazon amor corazon amor corazon fond corazon corazón je corazon je corazón un , le le un amor je corazon je corazon je , je corazon je , corazon corazón , corazon , corazón le le un corazon un , je amor un corazon le , un corazón\n",
      "\n",
      "\n",
      "EPOCH 2\n",
      "1000/7859\n",
      "2000/7859\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-98756afb1b40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-a909fec199d9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, max_epochs)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;31m#             nn.utils.clip_grad_norm_(model.parameters(), flags.gradients_norm)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, words, vocab_to_int, int_to_vocab,nbwords, top_k=5):\n",
    "    model.eval()\n",
    "    h = model.init_hidden(1)\n",
    "    \n",
    "    for w in words:\n",
    "        idx = th.LongTensor([[vocab_to_int[w]]])\n",
    "        out, h = model(idx, h)\n",
    "    \n",
    "    _, top_idx = th.topk(out[0], k=top_k)\n",
    "    choices = top_idx.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_vocab[choice])\n",
    "    \n",
    "    for _ in range(nbwords):\n",
    "        ix = th.LongTensor([[choice]])\n",
    "        out, h = model(idx, h)\n",
    "\n",
    "        _, top_idx = th.topk(out[0], k=top_k)\n",
    "        choices = top_idx.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words.append(int_to_vocab[choice])\n",
    "\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ couplet 1 ] et je zone , comme un loup j'ai trop faim , ouais de sous et je serre , comme un fou j'suis déter ' , levez-vous j'ai les cernes , je vois flou pour mes frères , j'me mets saoul franchement , je n'sais plus quoi faire trop d'jaloux j'peux plus les compter faire le mac , à quoi ça sert ? tu peux t'faire fumer ou planter j'charme les miss comme calimero en deux-deux j'prends cent numéros ça sert à rien de faire le héros toujours à la base comme mero mero et oui mi soir j'essaie m'en , c'est m'en d'garder ken d'garder c'est ken m'en ken j'essaie ken c'est j'essaie m'en c'est m'en m'en ken , m'en m'en j'essaie ] ken c'est j'essaie j'essaie\n"
     ]
    }
   ],
   "source": [
    "predict(model, token[:100], word2idx, idx2word, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shut', 'up', ',', 'steve', '.', 'l', 'have', 'a', 'term', 'paper', 'due', '.', 'oh', ',', 'yeah']\n"
     ]
    }
   ],
   "source": [
    "print(token[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(model3.state_dict(), \"model3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Model(nb_cells,hidden_dim, vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.load_state_dict(th.load(\"model3.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
