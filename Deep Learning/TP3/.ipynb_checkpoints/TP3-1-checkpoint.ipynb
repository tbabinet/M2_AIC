{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs that we will use\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch as th \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# To load the data we will use the script of Gaetan Marceau Caron\n",
    "# You can download it from the course webiste and move it to the same directory that contains this ipynb file\n",
    "import dataset_loader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download mnist dataset \n",
    "# if(\"mnist.pkl.gz\" not in os.listdir(\".\")):\n",
    "#     !wget http://deeplearning.net/data/mnist/mnist.pkl.gz\n",
    "\n",
    "# if you have it somewhere else, you can comment the lines above\n",
    "# and overwrite the path below\n",
    "mnist_path = \"../mnist.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the 3 splits\n",
    "train_data, dev_data, test_data = dataset_loader.load_mnist(mnist_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part one: MNIST classification with Pytorch\n",
    "The goal of the first part is to learn how to use Pytorch and to observe the impact of regularization during training. You should test different network architectures, e.g. with hidden layers of size 128-128, 128-64-32-16, 256-128-64-32-16, 512-256-128-64-32-16, 800-800, and different activation functions (tanh, relu, sigmoid).\n",
    "\n",
    "Remember that Pytorch expects data in a different format than in the previous lab exercise: the first dimension is always the batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784])\n",
      "torch.Size([1, 784])\n"
     ]
    }
   ],
   "source": [
    "image = th.from_numpy(train_data[0][0])\n",
    "print(image.shape) # flat image of dim (784,)\n",
    "\n",
    "# reshape the tensor so it is represented as a batch containing a single image\n",
    "# -1 means \"all remaining elements\", here it would be equivalent to image.reshape(1, 784)\n",
    "image = image.reshape(1, -1)\n",
    "print(image.shape) # flat image of dim (1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    }
   ],
   "source": [
    "# Constructing a batched input\n",
    "batch_size = 10\n",
    "first = 20\n",
    "\n",
    "# the cat() function concatenates a list of tensor along a dimension\n",
    "batch_input = th.cat(\n",
    "    [\n",
    "        # we reshape the image tensor so it has dimension (1, 784)\n",
    "        th.from_numpy(image).reshape(1, -1)\n",
    "        for image in train_data[0][first:first + batch_size]\n",
    "    ],\n",
    "    # we want to concatenate on the batch dimension\n",
    "    dim=0\n",
    ")\n",
    "print(batch_input.shape)  # batch of ten flat images (10, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Layer initialization¶\n",
    "By default, Pytorch will apply Kaiming initialization to linear layers. However, I recommend you to always explicitly initialize you network by hand in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5cb7ffba43c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlinear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# initialization are always in-place operations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# linear.weight is a Parameter, linear.weight.data is the tensor containing the parameter values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_uniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Xavier/Glorot init for tanh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bias' is not defined"
     ]
    }
   ],
   "source": [
    "linear = th.nn.Linear(10, 20, bias=bias)\n",
    "\n",
    "# initialization are always in-place operations\n",
    "# linear.weight is a Parameter, linear.weight.data is the tensor containing the parameter values\n",
    "th.nn.init.xavier_uniform_(linear.weight.data)  # Xavier/Glorot init for tanh\n",
    "th.nn.init.kaiming_uniform_(linear.weight.data)  # Kaiming/He init for tanh\n",
    "\n",
    "if bias:\n",
    "    th.nn.init.zeros_(linear.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Regularization\n",
    "\n",
    "You can try two types of regularization (they can be combined together):\n",
    "\n",
    "weight decay:��it is a parameter of the optimizer\n",
    "dropout: see slides\n",
    "\n",
    "## 1.4. Gradient clipping\n",
    "\n",
    "A commong trick for training neural networks is gradient clipping: if the norm of the gradient is too big, we rescale the gradient. This trick can be used to prevent exploding gradients and also to make \"too big steps\" in the wrong direction due the use of approximate gradient computation in SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-606b1de226f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# compute gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# clip gradient if its norm exceed 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_loss' is not defined"
     ]
    }
   ],
   "source": [
    "batch_loss.backward()  # compute gradient\n",
    "torch.nn.utils.clip_grad_value_(network.parameters(), 5.)  # clip gradient if its norm exceed 5\n",
    "optimizer.step()  # update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_1, self).__init__()\n",
    "        self.dense1 = nn.Linear(784, 128)\n",
    "        self.dense2 = nn.Linear(128, 10)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        nn.init.xavier_uniform_(self.dense1.weight.data)  # Xavier/Glorot init for tanh\n",
    "        nn.init.zeros_(self.dense1.bias.data)  # Xavier/Glorot init for tanh\n",
    "        nn.init.zeros_(self.dense2.bias.data)  # Xavier/Glorot init for tanh\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dropout(x)\n",
    "        return F.softmax(self.dense2(x), dim=1)\n",
    "    \n",
    "class Model_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_2, self).__init__()\n",
    "        self.dense1 = nn.Linear(784, 10)\n",
    "        nn.init.xavier_uniform_(self.dense1.weight.data)  # Xavier/Glorot init for tanh\n",
    "        nn.init.zeros_(self.dense1.bias.data)  # Xavier/Glorot init for tanh\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.softmax(self.dropout(self.dense1(x)), dim=1)\n",
    "    \n",
    "# 256-128-64-32-16    \n",
    "class Model_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_3, self).__init__()\n",
    "        self.dense1 = nn.Linear(784, 256)\n",
    "        self.dense2 = nn.Linear(256, 128)\n",
    "        self.dense3 = nn.Linear(128, 64)\n",
    "        self.dense4 = nn.Linear(64, 32)\n",
    "        self.dense5 = nn.Linear(32, 16)\n",
    "        self.dense6 = nn.Linear(16, 10)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.dense1.weight.data)  # Xavier/Glorot init for tanh\n",
    "        nn.init.zeros_(self.dense1.bias.data)  # Xavier/Glorot init for tanh\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.dense2.weight.data)  # Xavier/Glorot init for tanh\n",
    "        nn.init.zeros_(self.dense2.bias.data)  # Xavier/Glorot init for tanh\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.dense3.weight.data)  # Xavier/Glorot init for tanh\n",
    "        nn.init.zeros_(self.dense3.bias.data)  # Xavier/Glorot init for tanh\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.dense4.weight.data)  # Xavier/Glorot init for tanh\n",
    "        nn.init.zeros_(self.dense4.bias.data)  # Xavier/Glorot init for tanh\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.dense5.weight.data)  # Xavier/Glorot init for tanh\n",
    "        nn.init.zeros_(self.dense5.bias.data)  # Xavier/Glorot init for tanh\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.dense6.weight.data)  # Xavier/Glorot init for tanh\n",
    "        nn.init.zeros_(self.dense6.bias.data)  # Xavier/Glorot init for tanh\n",
    "        \n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.dense1(x))\n",
    "#         x = self.dropout(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "#         x = self.dropout(x)\n",
    "        x = F.relu(self.dense3(x))\n",
    "#         x = self.dropout(x)\n",
    "        x = F.relu(self.dense4(x))\n",
    "#         x = self.dropout(x)\n",
    "        x = F.relu(self.dense5(x))\n",
    "#         x = self.dropout(x)\n",
    "        return F.softmax(self.dropout(self.dense6(x)), dim=1)\n",
    "    \n",
    "class Model_4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_4, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(batch_size):\n",
    "    for i in range(0, len(train_data[0]), batch_size):\n",
    "        yield train_data[0][i:i+batch_size], train_data[1][i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "model1 = Model_1()\n",
    "batch_size = 10\n",
    "fn = nn.NLLLoss()\n",
    "max_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Model_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Model_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, batch_size, max_epochs=5, conv=False):\n",
    "    optim = th.optim.SGD(params=model.parameters(), lr =lr, weight_decay=1e-4)\n",
    "    model.train()\n",
    "    for i in range(max_epoch):\n",
    "        np.random.shuffle(idx)\n",
    "        accuracy = 0\n",
    "        mean_loss = 0\n",
    "        batches = get_batches(batch_size)\n",
    "        for x, y in batches:\n",
    "            if conv :\n",
    "                x = x.reshape(batch_size, 1, 28,28)\n",
    "            data = th.from_numpy(x)#.reshape(x.shape[0],x.shape[1],1))\n",
    "            label = th.LongTensor(y)\n",
    "            pred = model(data)\n",
    "            loss = fn(pred, label)\n",
    "\n",
    "            mean_loss+=loss.item()\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            _,p = th.max(pred,1)\n",
    "\n",
    "            accuracy+=len([1 for i, j in zip(label, p) if i == j])\n",
    "        print(\"EPOCH {}\".format(i+1))\n",
    "        print(\"Accuracy : \",accuracy/len(train_data[0]))\n",
    "        print(\"Mean loss : \",mean_loss/len(train_data[0]))\n",
    "        print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "Accuracy :  0.47382\n",
      "Mean loss :  -1899.6645382866263\n",
      "----------------------------------------\n",
      "EPOCH 2\n",
      "Accuracy :  0.70156\n",
      "Mean loss :  -3281.501865029335\n",
      "----------------------------------------\n",
      "EPOCH 3\n",
      "Accuracy :  0.75574\n",
      "Mean loss :  -3605.012201502919\n",
      "----------------------------------------\n",
      "EPOCH 4\n",
      "Accuracy :  0.8016\n",
      "Mean loss :  -3854.4228487312794\n",
      "----------------------------------------\n",
      "EPOCH 5\n",
      "Accuracy :  0.81262\n",
      "Mean loss :  -3942.9916238188744\n",
      "----------------------------------------\n",
      "EPOCH 6\n",
      "Accuracy :  0.82266\n",
      "Mean loss :  -4006.8974404633045\n",
      "----------------------------------------\n",
      "EPOCH 7\n",
      "Accuracy :  0.82558\n",
      "Mean loss :  -4037.788662701845\n",
      "----------------------------------------\n",
      "EPOCH 8\n",
      "Accuracy :  0.83016\n",
      "Mean loss :  -4068.9664451777935\n",
      "----------------------------------------\n",
      "EPOCH 9\n",
      "Accuracy :  0.83254\n",
      "Mean loss :  -4086.0620645284653\n",
      "----------------------------------------\n",
      "EPOCH 10\n",
      "Accuracy :  0.83536\n",
      "Mean loss :  -4103.097301006317\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train(model1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tbabi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "Accuracy :  0.49768\n",
      "Mean loss :  -2482.722016237676\n",
      "----------------------------------------\n",
      "EPOCH 2\n",
      "Accuracy :  0.49992\n",
      "Mean loss :  -2498.326222091913\n",
      "----------------------------------------\n",
      "EPOCH 3\n",
      "Accuracy :  0.50252\n",
      "Mean loss :  -2508.5511846393347\n",
      "----------------------------------------\n",
      "EPOCH 4\n",
      "Accuracy :  0.50498\n",
      "Mean loss :  -2524.6669537201524\n",
      "----------------------------------------\n",
      "EPOCH 5\n",
      "Accuracy :  0.50866\n",
      "Mean loss :  -2543.958852380514\n",
      "----------------------------------------\n",
      "EPOCH 6\n",
      "Accuracy :  0.50936\n",
      "Mean loss :  -2547.138530880213\n",
      "----------------------------------------\n",
      "EPOCH 7\n",
      "Accuracy :  0.514\n",
      "Mean loss :  -2568.0107804089785\n",
      "----------------------------------------\n",
      "EPOCH 8\n",
      "Accuracy :  0.51412\n",
      "Mean loss :  -2563.2451852038503\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-45509fb2fd6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-50-184e710c1290>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, max_epochs)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-007cb7dc141f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "Accuracy :  0.35084\n",
      "Mean loss :  -0.03299043372314423\n",
      "----------------------------------------\n",
      "EPOCH 2\n",
      "Accuracy :  0.51066\n",
      "Mean loss :  -0.05074212283015251\n",
      "----------------------------------------\n",
      "EPOCH 3\n",
      "Accuracy :  0.53664\n",
      "Mean loss :  -0.05367386571764946\n",
      "----------------------------------------\n",
      "EPOCH 4\n",
      "Accuracy :  0.54456\n",
      "Mean loss :  -0.05465708997815848\n",
      "----------------------------------------\n",
      "EPOCH 5\n",
      "Accuracy :  0.55368\n",
      "Mean loss :  -0.055373174402713776\n",
      "----------------------------------------\n",
      "EPOCH 6\n",
      "Accuracy :  0.55954\n",
      "Mean loss :  -0.056128567058146\n",
      "----------------------------------------\n",
      "EPOCH 7\n",
      "Accuracy :  0.55802\n",
      "Mean loss :  -0.056090947017371655\n",
      "----------------------------------------\n",
      "EPOCH 8\n",
      "Accuracy :  0.5637\n",
      "Mean loss :  -0.05654029991388321\n",
      "----------------------------------------\n",
      "EPOCH 9\n",
      "Accuracy :  0.56546\n",
      "Mean loss :  -0.05670385486841202\n",
      "----------------------------------------\n",
      "EPOCH 10\n",
      "Accuracy :  0.57232\n",
      "Mean loss :  -0.057393597545027736\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train(model3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "Accuracy :  0.55366\n",
      "Mean loss :  -0.04659384910196066\n",
      "----------------------------------------\n",
      "EPOCH 2\n",
      "Accuracy :  0.84\n",
      "Mean loss :  -0.08310517079651356\n",
      "----------------------------------------\n",
      "EPOCH 3\n",
      "Accuracy :  0.93874\n",
      "Mean loss :  -0.09306505871772766\n",
      "----------------------------------------\n",
      "EPOCH 4\n",
      "Accuracy :  0.9578\n",
      "Mean loss :  -0.09525022202134133\n",
      "----------------------------------------\n",
      "EPOCH 5\n",
      "Accuracy :  0.96704\n",
      "Mean loss :  -0.0962427853679657\n",
      "----------------------------------------\n",
      "EPOCH 6\n",
      "Accuracy :  0.9724\n",
      "Mean loss :  -0.09682691614866257\n",
      "----------------------------------------\n",
      "EPOCH 7\n",
      "Accuracy :  0.97638\n",
      "Mean loss :  -0.09727106639027595\n",
      "----------------------------------------\n",
      "EPOCH 8\n",
      "Accuracy :  0.97918\n",
      "Mean loss :  -0.09759943298101426\n",
      "----------------------------------------\n",
      "EPOCH 9\n",
      "Accuracy :  0.98174\n",
      "Mean loss :  -0.09786574044585228\n",
      "----------------------------------------\n",
      "EPOCH 10\n",
      "Accuracy :  0.98324\n",
      "Mean loss :  -0.09806167255043984\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train(model4, 10, conv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(model4.state_dict(), \"conv_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Bonus: Convolutional Neural Network\n",
    "\n",
    "You can try to rely on a CNN instead of a MLP to classify MNIST images (you can still have a single layer MLP on top of convolutions, after pooling!). Note that this will requires you to reshape the input images!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Variational Auto-Encoder\n",
    "\n",
    "To build a new Variational Auto-Encoder, you need two networks:\n",
    "\n",
    "- An encoder that will take as input an image and compute the parameters of list of Normal distributions\n",
    "- A decoder that will take a sample from each Normal distribution and will output an image\n",
    "\n",
    "For simplicity we will assume that:\n",
    "\n",
    "- each network as a single hidden layer of size 100\n",
    "- the latent space contains only 2 points\n",
    "\n",
    "To understand exactly what a VAE is, you can:\n",
    "\n",
    "\n",
    "- check the slides of Michèle Sebag\n",
    "- check this tutorial: https://arxiv.org/abs/1606.05908\n",
    "\n",
    "## 1.2. Encoder\n",
    "- Compute an hidden representation:  $z = relu(W^1x+b^1)$\n",
    "- Compute the means of the normal distributions:  $mu=W^2x+b^2$\n",
    "- Compute the log variance of the normal distributions:  $log_{sigmasquared}=W^3x+b^3$\n",
    "\n",
    "## 1.2. Decoder\n",
    "This a simple MLP, nothing new here!\n",
    "\n",
    "## 1.3. Training loss\n",
    "To compute the training loss, you must compute two terms:\n",
    "\n",
    "- a Monte-Carlo estimation of the reconstruction loss\n",
    "- the KL divergence between the distributions computed by the encoder and the prior\n",
    "\n",
    "To sample values, you can use the reparameterization trick as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.normal(0, 1., mu.shape)\n",
    "z = mu + e * torch.sqrt(torch.exp(log_sigma_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the reconstruction loss, use the Binary Cross Entropy loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-7789562c412b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss_builder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sum\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "loss_builder = torch.nn.BCEWithLogitsLoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula of the KL divergence with the prior is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-0.5 * torch.sum(1 + log_sigma_squared - mu.pow(2) - log_sigma_squared.exp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Recomended hyper parameters\n",
    "- Optimizer: Adam\n",
    "- N. epochs: 50\n",
    "- Use gradient clipping!\n",
    "- Large batch size, e.g. 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use itertools.chain to join parameters of the two networks\n",
    "optimizer = torch.optim.Adam(itertools.chain(encoder.parameters(), decoder.parameters()))\n",
    "torch.nn.utils.clip_grad_value_(itertools.chain(encoder.parameters(), decoder.parameters()), 5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Generate new images\n",
    "Note: they will be blurry, but that's ok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.normal(0, 1., (10, 2))\n",
    "images = decoder(e).sigmoid()\n",
    "\n",
    "for i in range(10):\n",
    "    picture = images[i].clone().detach().numpy()\n",
    "    plt.imshow(picture.reshape(28,28), cmap='Greys')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
